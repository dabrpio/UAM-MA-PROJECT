# Fine Tuning Large Language Models by Domain Adaptation on the Fly

This project demonstrates the fine-tuning of large language models (LLMs) for translation tasks through domain adaptation on the fly. The application enables translation between Polish and English, leveraging in-context learning with few-shot examples, dynamically created based on a translation memory.

## Features

- **Frontend**: Built using React and Vite for a modern and responsive user interface.
- **Backend**: Powered by FastAPI to handle translation requests efficiently.
- **LLM-based Translations**: Translations are generated by a large language model (GPT) using few-shot in-context learning.
- **Translation Memory**: The project utilizes a translation memory built from the DGT corpus for Polish-English translation tasks.
- **Fuzzy Matching**: Uses the `ratio` method from the RapidFuzz library to calculate Indel distance and find the n most similar sentences in the translation memory.

## How It Works

1. **Sentence Input**: Users input a sentence they wish to translate between Polish and English and specify how many translation examples should be included in the prompt.
2. **Fuzzy Matching**: The system searches for fuzzy matches in the translation memory using the RapidFuzz library's `ratio` method.
3. **Few-shot Examples**: The system uses n most similar sentences to create few-shot examples for in-context learning.
4. **LLM Translation**: The large language model generates a translation based on these examples.
5. **Output**: There are two results. First one is the translation leveraging few-shot prompting. The second one is the zero-shot translation for comparison. Additionally examples used in few-shot prompt are displayed with their similarity score.

## Technologies Used

- **Frontend**: [React](https://react.dev/), [Vite](https://vitejs.dev/), [Zod](https://zod.dev/), [React Hook Form](https://react-hook-form.com/), [shadcn/ui](https://ui.shadcn.com/), [tailwindcss](https://tailwindcss.com/)
- **Backend**: [FastAPI](https://fastapi.tiangolo.com/)
- **Large Language Model**: [GPT-4o-mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
- **Translation Memory**: [DGT corpus](https://opus.nlpl.eu/DGT/en&pl/v2019/DGT)
- **Fuzzy Matching**: [RapidFuzz (normalized Indel distance)](https://rapidfuzz.github.io/RapidFuzz/Usage/fuzz.html)

## Setup and Installation

Prerequisites:

- Install [Python](https://www.python.org/)
- Install [Node](https://nodejs.org/en) in v20 LTS.

To set up and run the project locally:

1. Clone this repository.
2. Setup and run backend:

```bash
cd backend

# Create Python virtual environment and activate it
python3 -m venv .venv
source .venv/bin/activate

# Install the dependencies
pip install -r requirements.txt

# Create .env file based on .env.template and fill required environment variables:
cp .env.template .env

# Start the backend:
uvicorn main:app --reload
```

3. Setup and run frontend:

```bash
cd frontend

# Install the dependencies for frontend:
npm install

# Create .env file based on .env.template and fill required environment variables:
cp .env.template .env

# Start the frontend:
npm run dev
```

4. Open the app in your browser. It is on http://localhost:5173/.
